{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8be6cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install os\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b933570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70e2af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fd6997c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['API_KEY']='your_api_key'\n",
    "openai.api_key=os.getenv('API_KEY')\n",
    "print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5069fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # text-davinci-002- This is an older version of the davinci engine and may have some differences in performance and behavior compared to the latest davinci engine\n",
    "response=openai.Completion.create(\n",
    "    engine=\"text-davinci-002\",\n",
    "    prompt=\"What is AI\",\n",
    "    max_tokens=500\n",
    ")\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14e7ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # davinci- This is a versatile engine capable of handling a wide range of tasks and prompts. It's suitable for most use cases and is a good default choice.\n",
    "response=openai.Completion.create(\n",
    "    engine=\"davinci\",\n",
    "    prompt=\"What is AI\",\n",
    "    max_tokens=500\n",
    ")\n",
    "# print(response) #this will basically give the whole lot of response including every feature in the openai output \n",
    "print(response.choices[0].text.strip()) #this will only give the text geerated in the choices part of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0812f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # curie- This engine is designed for everyday use cases and offers a balance between cost and performance. It can handle a variety of tasks effectively.\n",
    "response=openai.Completion.create(\n",
    "    engine=\"curie\",\n",
    "    prompt=\"Once upon a time\",\n",
    "    max_tokens=500\n",
    ")\n",
    "# print(response)\n",
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bd7ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # babbage- This engine is a more cost-effective option for basic tasks and shorter responses. It may have slightly lower performance compared to davinci and curie.\n",
    "response=openai.Completion.create(\n",
    "    engine=\"babbage\",\n",
    "    prompt=\"Who first invented AI?\",\n",
    "    max_tokens=500\n",
    ")\n",
    "print(response.choices[0].text[1:].strip())\n",
    "# print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf1e3b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=openai.Completion.create(\n",
    "    engine = \"text-davinci-003\",\n",
    "    prompt = \"What is AI?\",\n",
    "    max_tokens = 1000,\n",
    ")\n",
    "print(response.choices[0].text[:].strip())\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05f49016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #copyyyyyyyyyyyy forrrrrrrr checkkkkkkkkkkkkk\n",
    "\n",
    "response=openai.Completion.create(\n",
    "    engine = \"text-davinci-003\",\n",
    "    prompt = \"AI?\",\n",
    "    max_tokens = 1000,\n",
    ")\n",
    "print(response.choices[0].text[:].strip())\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4e2d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # These are the unique information of a particular response\n",
    "print(\"Model\", response.model)\n",
    "print(\"Created\", response.created)\n",
    "print(\"ID\", response.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "189044c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e7e6904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the role of system, use and the assitant.\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\" : \"system\", \"content\" : \"You are a brilliant assistant that speaks in english language\"},\n",
    "    {\"role\" : \"user\", \"content\" : \"What is AI?\"},\n",
    "    {\"role\" : \"assistant\", \"content\" : \"You are always going to start the conversation with, 'Hello! Here is your answer'  \"}\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1a2a349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! AI stands for Artificial Intelligence. It refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. AI encompasses various fields such as machine learning, natural language processing, computer vision, and robotics. Its goal is to create intelligent systems that can perform tasks without explicit human instructions and can adapt and improve their performance over time. AI has wide-ranging applications in areas such as healthcare, finance, transportation, and entertainment.\n"
     ]
    }
   ],
   "source": [
    "response=openai.ChatCompletion.create(\n",
    "    model= \"gpt-3.5-turbo\",\n",
    "    messages=messages\n",
    ")\n",
    "# print(response.choices[0])\n",
    "print(response.choices[0][\"message\"][\"content\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee694bb",
   "metadata": {},
   "source": [
    "ChatGPT generated code:-\n",
    "\n",
    "AI, or Artificial Intelligence, refers to the simulation of human intelligence in machines that are programmed to think and learn like humans. It encompasses a wide range of technologies and techniques that allow computers and machines to perform tasks that typically require human intelligence. AI systems can analyze data, make decisions, solve problems, and even interact with humans in natural language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f00b8536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     {\"role\" : \"system\", \n",
    "#         \"content\" : (\n",
    "#             \"You are a brilliant assistant that speaks in English language.\\n\"\n",
    "#             \"You have great knowledge about technologies.\"\n",
    "#                     )\n",
    "#     },\n",
    "    \n",
    "#     {\"role\" : \"user\", \n",
    "#      \"content\" : \"What is suppervised learning?\"},\n",
    "#     {\"role\" : \"assistant\", \"content\" : \"You are always going to start the conversation with, 'Hello! Here is your answer'  \"}\n",
    "\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d43f5bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Enter the role of the system\")\n",
    "a=input()\n",
    "print(\"Enter your Question\")\n",
    "b=input()\n",
    "messages = [\n",
    "    {\"role\" : \"system\", \n",
    "        \"content\" : (\n",
    "                    a\n",
    "                    )\n",
    "    },\n",
    "    \n",
    "    {\"role\" : \"user\", \n",
    "     \"content\" : b}    \n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0db4907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=openai.ChatCompletion.create(\n",
    "    model= \"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    max_tokens=3700\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c77e65f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\": \"assistant\",\n",
    "    \"content\":response.choices[0][\"message\"][\"content\"] #basically in this we are giving the output of the previous instruction as a context to next question/ instruction\n",
    "})\n",
    "\n",
    "print(response.choices[0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d5e3819",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\":\"What about unsupervised learning?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd23e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking user input\n",
    "\n",
    "print(\"Enter your question: \")\n",
    "messages.append({\n",
    "    \"role\": \"user\",\n",
    "    \"content\":input() \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=openai.ChatCompletion.create(\n",
    "    model= \"gpt-3.5-turbo\",\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa761560",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.choices[0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba36daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#temperature always betweeen 0 and 2\n",
    "#high temperature- higher randomness of the output (close to 2)\n",
    "response=openai.ChatCompletion.create(\n",
    "    model= \"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    temperature=1.7,\n",
    "    max_tokens=1500\n",
    ")\n",
    "print(\"High temperature: \", response.choices[0][\"message\"][\"content\"])\n",
    "\n",
    "#low  temperature- more deterministic output (close to 0)\n",
    "response=openai.ChatCompletion.create(\n",
    "    model= \"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    temperature=0,\n",
    "    max_tokens=1600\n",
    ")\n",
    "print(\"\\nLow temperature: \", response.choices[0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41143c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received an error from OpenAi API: This model's maximum context length is 4097 tokens. However, you requested 6058 tokens (58 in the messages, 6000 in the completion). Please reduce the length of the messages or completion.\n"
     ]
    }
   ],
   "source": [
    "#Exception handling- resource exhausted (token exceed), unauthorised, bad request, rate limit exceeded\n",
    "\n",
    "messages = [\n",
    "    {\"role\" : \"system\", \n",
    "        \"content\" : (\n",
    "            \"You are a brilliant assistant that speaks in English language.\\n\"\n",
    "            \"You have great knowledge about technologies.\"\n",
    "                    )\n",
    "    },\n",
    "    \n",
    "    {\"role\" : \"user\", \n",
    "     \"content\" : \"What is suppervised learning?\"},\n",
    "    {\"role\" : \"assistant\", \"content\" : \"You are always going to start the conversation with, 'Hello! Here is your answer'  \"}\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "try:\n",
    "    response=openai.ChatCompletion.create(\n",
    "        model= \"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        max_tokens=6000\n",
    "    )\n",
    "    print(response.choices[0][\"message\"][\"content\"])\n",
    "    \n",
    "except Exception as a:\n",
    "    print(f\"Received an error from OpenAi API: {a}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f51974",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
